{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "categorizenews.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "2H9voXhrZkm5",
        "colab_type": "code",
        "outputId": "0b4e1e50-1dda-4141-cb4f-7d8ed0800841",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "import pandas as pd\n",
        "from google.colab import files\n",
        "import io\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "#uploaded = files.upload()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8_CxgXTM1qRH",
        "colab_type": "code",
        "outputId": "db45d87b-11fa-4626-e035-050e1e6591c2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 782
        }
      },
      "source": [
        "path = '/content/gdrive/My Drive/'\n",
        "!ls '/content/gdrive/My Drive/training_data_categories/tech'"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "001.txt  046.txt  091.txt  136.txt  181.txt  226.txt  271.txt  316.txt\t361.txt\n",
            "002.txt  047.txt  092.txt  137.txt  182.txt  227.txt  272.txt  317.txt\t362.txt\n",
            "003.txt  048.txt  093.txt  138.txt  183.txt  228.txt  273.txt  318.txt\t363.txt\n",
            "004.txt  049.txt  094.txt  139.txt  184.txt  229.txt  274.txt  319.txt\t364.txt\n",
            "005.txt  050.txt  095.txt  140.txt  185.txt  230.txt  275.txt  320.txt\t365.txt\n",
            "006.txt  051.txt  096.txt  141.txt  186.txt  231.txt  276.txt  321.txt\t366.txt\n",
            "007.txt  052.txt  097.txt  142.txt  187.txt  232.txt  277.txt  322.txt\t367.txt\n",
            "008.txt  053.txt  098.txt  143.txt  188.txt  233.txt  278.txt  323.txt\t368.txt\n",
            "009.txt  054.txt  099.txt  144.txt  189.txt  234.txt  279.txt  324.txt\t369.txt\n",
            "010.txt  055.txt  100.txt  145.txt  190.txt  235.txt  280.txt  325.txt\t370.txt\n",
            "011.txt  056.txt  101.txt  146.txt  191.txt  236.txt  281.txt  326.txt\t371.txt\n",
            "012.txt  057.txt  102.txt  147.txt  192.txt  237.txt  282.txt  327.txt\t372.txt\n",
            "013.txt  058.txt  103.txt  148.txt  193.txt  238.txt  283.txt  328.txt\t373.txt\n",
            "014.txt  059.txt  104.txt  149.txt  194.txt  239.txt  284.txt  329.txt\t374.txt\n",
            "015.txt  060.txt  105.txt  150.txt  195.txt  240.txt  285.txt  330.txt\t375.txt\n",
            "016.txt  061.txt  106.txt  151.txt  196.txt  241.txt  286.txt  331.txt\t376.txt\n",
            "017.txt  062.txt  107.txt  152.txt  197.txt  242.txt  287.txt  332.txt\t377.txt\n",
            "018.txt  063.txt  108.txt  153.txt  198.txt  243.txt  288.txt  333.txt\t378.txt\n",
            "019.txt  064.txt  109.txt  154.txt  199.txt  244.txt  289.txt  334.txt\t379.txt\n",
            "020.txt  065.txt  110.txt  155.txt  200.txt  245.txt  290.txt  335.txt\t380.txt\n",
            "021.txt  066.txt  111.txt  156.txt  201.txt  246.txt  291.txt  336.txt\t381.txt\n",
            "022.txt  067.txt  112.txt  157.txt  202.txt  247.txt  292.txt  337.txt\t382.txt\n",
            "023.txt  068.txt  113.txt  158.txt  203.txt  248.txt  293.txt  338.txt\t383.txt\n",
            "024.txt  069.txt  114.txt  159.txt  204.txt  249.txt  294.txt  339.txt\t384.txt\n",
            "025.txt  070.txt  115.txt  160.txt  205.txt  250.txt  295.txt  340.txt\t385.txt\n",
            "026.txt  071.txt  116.txt  161.txt  206.txt  251.txt  296.txt  341.txt\t386.txt\n",
            "027.txt  072.txt  117.txt  162.txt  207.txt  252.txt  297.txt  342.txt\t387.txt\n",
            "028.txt  073.txt  118.txt  163.txt  208.txt  253.txt  298.txt  343.txt\t388.txt\n",
            "029.txt  074.txt  119.txt  164.txt  209.txt  254.txt  299.txt  344.txt\t389.txt\n",
            "030.txt  075.txt  120.txt  165.txt  210.txt  255.txt  300.txt  345.txt\t390.txt\n",
            "031.txt  076.txt  121.txt  166.txt  211.txt  256.txt  301.txt  346.txt\t391.txt\n",
            "032.txt  077.txt  122.txt  167.txt  212.txt  257.txt  302.txt  347.txt\t392.txt\n",
            "033.txt  078.txt  123.txt  168.txt  213.txt  258.txt  303.txt  348.txt\t393.txt\n",
            "034.txt  079.txt  124.txt  169.txt  214.txt  259.txt  304.txt  349.txt\t394.txt\n",
            "035.txt  080.txt  125.txt  170.txt  215.txt  260.txt  305.txt  350.txt\t395.txt\n",
            "036.txt  081.txt  126.txt  171.txt  216.txt  261.txt  306.txt  351.txt\t396.txt\n",
            "037.txt  082.txt  127.txt  172.txt  217.txt  262.txt  307.txt  352.txt\t397.txt\n",
            "038.txt  083.txt  128.txt  173.txt  218.txt  263.txt  308.txt  353.txt\t398.txt\n",
            "039.txt  084.txt  129.txt  174.txt  219.txt  264.txt  309.txt  354.txt\t399.txt\n",
            "040.txt  085.txt  130.txt  175.txt  220.txt  265.txt  310.txt  355.txt\t400.txt\n",
            "041.txt  086.txt  131.txt  176.txt  221.txt  266.txt  311.txt  356.txt\t401.txt\n",
            "042.txt  087.txt  132.txt  177.txt  222.txt  267.txt  312.txt  357.txt\n",
            "043.txt  088.txt  133.txt  178.txt  223.txt  268.txt  313.txt  358.txt\n",
            "044.txt  089.txt  134.txt  179.txt  224.txt  269.txt  314.txt  359.txt\n",
            "045.txt  090.txt  135.txt  180.txt  225.txt  270.txt  315.txt  360.txt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hS27z2MZwe8F",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "'''\n",
        "tech = pd.DataFrame()\n",
        "\n",
        "\n",
        "directories = ['tech', 'sport', 'politics', 'entertainment', 'business']\n",
        "#directories = ['tech']\n",
        "\n",
        "def gather_data(target_dir, name):\n",
        "    category_name = name + '_data'\n",
        "    \n",
        "    articles = pd.DataFrame()\n",
        "    \n",
        "    for file_ in os.listdir(target_dir)[:20]:\n",
        "        with open(target_dir + \"/\"+ file_) as f:\n",
        "            textf = \" \".join(line.strip() for line in f)\n",
        "        articles = pd.concat([articles,pd.DataFrame(data = {name : [textf]})])\n",
        "    return articles\n",
        "\n",
        "for name in directories:\n",
        "  \n",
        "  directory_path = '/content/gdrive/My Drive/training_data_categories/'+name+'/'\n",
        "  #print(directory)\n",
        "  directory = gather_data(directory_path, name)\n",
        "  print(\"DIR\", directory)\n",
        "\n",
        "'''\n",
        "tech_dir = '/content/gdrive/My Drive/training_data_categories/tech/'\n",
        "sports_dir = '/content/gdrive/My Drive/training_data_categories/sport/'\n",
        "politics_dir = '/content/gdrive/My Drive/training_data_categories/politics/'\n",
        "entertainment_dir = '/content/gdrive/My Drive/training_data_categories/entertainment/'\n",
        "business_dir = '/content/gdrive/My Drive/training_data_categories/business/'\n",
        "\n",
        "directories = ['tech', 'sport', 'politics', 'entertainment', 'business']\n",
        "\n",
        "def gather_data(target_dir, name):\n",
        "    tech_data = pd.DataFrame()\n",
        "    for file_ in os.listdir(target_dir):\n",
        "        try:\n",
        "          with open(target_dir + \"/\"+ file_) as f:\n",
        "              textf = \" \".join(line.strip() for line in f)\n",
        "          tech_data = pd.concat([tech_data,pd.DataFrame(data = {'text' : [textf]})])\n",
        "        except Exception:\n",
        "          continue\n",
        "    return tech_data\n",
        "tech = gather_data(tech_dir, 'tech')\n",
        "sports = gather_data(sports_dir, 'sports')\n",
        "politics = gather_data(politics_dir, 'politics')\n",
        "entertainment = gather_data(entertainment_dir, 'entertainment')\n",
        "business = gather_data(business_dir, 'business')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t7cv3CIy74to",
        "colab_type": "code",
        "outputId": "0b1156b6-5b3b-4083-e486-2ec4ada115f3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "sports.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(510, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 213
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L_tO3aPv9PHw",
        "colab_type": "code",
        "outputId": "7f2b9346-ab76-4ca2-95ea-2f17b2558c43",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "business.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>WorldCom director admits lying  The former chi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Turkey-Iran mobile deal 'at risk'  Turkey's in...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Ebbers denies WorldCom fraud  Former WorldCom ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Parmalat to return to stockmarket  Parmalat, t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>UK economy facing 'major risks'  The UK manufa...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                text\n",
              "0  WorldCom director admits lying  The former chi...\n",
              "0  Turkey-Iran mobile deal 'at risk'  Turkey's in...\n",
              "0  Ebbers denies WorldCom fraud  Former WorldCom ...\n",
              "0  Parmalat to return to stockmarket  Parmalat, t...\n",
              "0  UK economy facing 'major risks'  The UK manufa..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 195
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lH-c8oAqILM7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tech['label'] = 'tech'\n",
        "sports['label'] = 'sports'\n",
        "politics['label'] = 'politics'\n",
        "entertainment['label'] = 'entertainment'\n",
        "business['label'] = 'business'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S76QTb58ILo2",
        "colab_type": "code",
        "outputId": "bed13a51-1e36-4d31-fd70-6337b568ffc6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "tech.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Broadband steams ahead in the US  More and mor...</td>\n",
              "      <td>tech</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Mobiles rack up 20 years of use  Mobile phones...</td>\n",
              "      <td>tech</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>EA to take on film and TV giants  Video game g...</td>\n",
              "      <td>tech</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Microsoft releases patches  Microsoft has warn...</td>\n",
              "      <td>tech</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Sony PSP console hits US in March  US gamers w...</td>\n",
              "      <td>tech</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                text label\n",
              "0  Broadband steams ahead in the US  More and mor...  tech\n",
              "0  Mobiles rack up 20 years of use  Mobile phones...  tech\n",
              "0  EA to take on film and TV giants  Video game g...  tech\n",
              "0  Microsoft releases patches  Microsoft has warn...  tech\n",
              "0  Sony PSP console hits US in March  US gamers w...  tech"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 197
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qiR31J8SGaDj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tech.reset_index(drop=True, inplace=True)\n",
        "sports.reset_index(drop=True, inplace=True)\n",
        "politics.reset_index(drop=True, inplace=True)\n",
        "entertainment.reset_index(drop=True, inplace=True)\n",
        "business.reset_index(drop=True, inplace=True)\n",
        "\n",
        "data = pd.concat([tech, sports, politics, entertainment, business], axis=0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wOmOBA-AGibW",
        "colab_type": "code",
        "outputId": "c613e0ff-9a0e-4679-dc8c-494560a0f065",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        }
      },
      "source": [
        "data.head(500)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Broadband steams ahead in the US  More and mor...</td>\n",
              "      <td>tech</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Mobiles rack up 20 years of use  Mobile phones...</td>\n",
              "      <td>tech</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>EA to take on film and TV giants  Video game g...</td>\n",
              "      <td>tech</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Microsoft releases patches  Microsoft has warn...</td>\n",
              "      <td>tech</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Sony PSP console hits US in March  US gamers w...</td>\n",
              "      <td>tech</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>94</th>\n",
              "      <td>Robertson out to retain Euro lure  Hearts mana...</td>\n",
              "      <td>sports</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>95</th>\n",
              "      <td>Safin relieved at Aussie recovery  Marat Safin...</td>\n",
              "      <td>sports</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>96</th>\n",
              "      <td>European medal chances improve  What have the ...</td>\n",
              "      <td>sports</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>97</th>\n",
              "      <td>Tomlinson stays focused on Europe  Long jumper...</td>\n",
              "      <td>sports</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>98</th>\n",
              "      <td>Wales critical of clumsy Grewcock  Wales coach...</td>\n",
              "      <td>sports</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>500 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                 text   label\n",
              "0   Broadband steams ahead in the US  More and mor...    tech\n",
              "1   Mobiles rack up 20 years of use  Mobile phones...    tech\n",
              "2   EA to take on film and TV giants  Video game g...    tech\n",
              "3   Microsoft releases patches  Microsoft has warn...    tech\n",
              "4   Sony PSP console hits US in March  US gamers w...    tech\n",
              "..                                                ...     ...\n",
              "94  Robertson out to retain Euro lure  Hearts mana...  sports\n",
              "95  Safin relieved at Aussie recovery  Marat Safin...  sports\n",
              "96  European medal chances improve  What have the ...  sports\n",
              "97  Tomlinson stays focused on Europe  Long jumper...  sports\n",
              "98  Wales critical of clumsy Grewcock  Wales coach...  sports\n",
              "\n",
              "[500 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 216
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_w-DPLfOMGtQ",
        "colab_type": "code",
        "outputId": "c52b9ed6-7eae-49d9-d38d-ca1a4e8bcc04",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "data.isnull().sum()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "text     0\n",
              "label    0\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 217
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dYyomoCuHP2L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk import pos_tag\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from collections import defaultdict\n",
        "from nltk.corpus import wordnet as wn\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn import model_selection, naive_bayes, svm\n",
        "from sklearn.metrics import accuracy_score"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uHs_bWZPHSEg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(data['text'], data['label'],test_size=0.3)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "snBPlTzpIXVi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Encoder = LabelEncoder()\n",
        "y_train = Encoder.fit_transform(y_train)\n",
        "y_test = Encoder.fit_transform(y_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Z51Xx8LIbYC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Tfidf_vect = TfidfVectorizer(max_features=5000)\n",
        "Tfidf_vect.fit(data['text'])\n",
        "Train_X_Tfidf = Tfidf_vect.transform(x_train)\n",
        "Test_X_Tfidf = Tfidf_vect.transform(x_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PeCbQBjwIdSS",
        "colab_type": "code",
        "outputId": "cf84c502-7214-4642-a327-8c0d5dc95d87",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# fit the training dataset on the NB classifier\n",
        "Naive = naive_bayes.MultinomialNB()\n",
        "Naive.fit(Train_X_Tfidf,y_train)\n",
        "# predict the labels on validation dataset\n",
        "predictions_NB = Naive.predict(Test_X_Tfidf)\n",
        "# Use accuracy_score function to get the accuracy\n",
        "print(\"Naive Bayes Accuracy Score -> \",accuracy_score(predictions_NB, y_test)*100)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Naive Bayes Accuracy Score ->  96.7065868263473\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jPrIpukNIgI7",
        "colab_type": "code",
        "outputId": "c2cfcd8a-065d-45d5-d216-8d8dd0adc525",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "text=[\"rockets, science, physics, windows\"]\n",
        "testing = Tfidf_vect.transform(text)\n",
        "Naive.predict(testing)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([4])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 230
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "34lpzTCjMr5w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pickle\n",
        "# save the model to disk\n",
        "filename = 'categorizer_model.sav'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BczW4mDYMu1j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pickled = pickle.dump(Naive, open(filename, 'wb'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9rhqHhEpMxpN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "files.download(filename)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Hn-MXBzMzrn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pkl_filename = \"pickle_model.pkl\"\n",
        "with open(pkl_filename, 'wb') as file:\n",
        "    pickle.dump(Naive, file)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yHAeJHmcM1wH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "files.download(pkl_filename)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Xnz7am5M4p7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data.to_csv('train_test.csv')\n",
        "files.download('train_test.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xg4RrHj4M8ab",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pkl_filename = \"Tfidf_vect.pkl\"\n",
        "with open(pkl_filename, 'wb') as file:\n",
        "    pickle.dump(Tfidf_vect, file)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CSyM14zIM_Z1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "files.download(pkl_filename)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bTdety6INBfc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pkl_filename2 = \"vocabulary.pkl\"\n",
        "with open(pkl_filename2, 'wb') as file:\n",
        "    pickle.dump(Tfidf_vect.vocabulary_, file)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QtQixGHaNCX7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "files.download(pkl_filename2)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}